{"file_contents":{"routes/index.js":{"content":"const chatRoute = require('./chat.route');\n\nmodule.exports = (app) => {\n    app.use('/api', chatRoute);\n};\n","size_bytes":107},"index.js":{"content":"require('dotenv').config()\n\nconst express = require('express')\nconst loadDb = require('./config/loadDb')\nconst bodyParser = require('body-parser')\nconst cors = require('cors')\nconst app = express()\n\n\n// loadDb.connect()\napp.use(cors())\nconst route = require('./routes/index')\napp.use(bodyParser.json())\n\nroute(app)\n\napp.listen(5000)","size_bytes":332},"config/loadDb.js":{"content":"const { DataAPIClient } = require('@datastax/astra-db-ts');\nconst { PuppeteerWebBaseLoader } = require('@langchain/community/document_loaders/web/puppeteer');\nconst { RecursiveCharacterTextSplitter } = require('langchain/text_splitter');\nconst { openai } = require(\"../controllers/chat.controller\");\n\nmodule.exports.connect = async () => {\n    try {\n        const endpoint = process.env.ASTRA_DB_ENDPOINT;\n        const token = process.env.ASTRA_DB_APPLICATION_TOKEN;\n        if (!endpoint || !token) {\n            throw new Error('Missing ASTRA_DB_ENDPOINT or ASTRA_DB_APPLICATION_TOKEN in .env. Check Astra Console.');\n        }\n        console.log('Endpoint:', endpoint);\n\n        const client = new DataAPIClient();\n        const db = client.db(endpoint, { token });\n        console.log('Connected to DB ID:', db.id);\n\n        const SimilarityMetric = \"dot_product\";\n        const data = [\n            'https://vi.wikipedia.org/wiki/Qu%E1%BA%A3_b%C3%B3ng_v%C3%A0ng_ch%C3%A2u_%C3%82u_2025',\n            'https://vi.wikipedia.org/wiki/2_ng%C3%A0y_1_%C4%91%C3%AAm_(m%C3%B9a_4)',\n            'https://vi.wikipedia.org/wiki/Ng%C3%A2n_98',\n            'https://nhandan.vn/tu-vu-an-nam-sinh-dam-ban-tu-vong-canh-bao-phap-ly-cho-nguoi-chua-thanh-nien-post916515.html'\n        ];\n\n        const splitter = new RecursiveCharacterTextSplitter({\n            chunkSize: 512,\n            chunkOverlap: 100\n        });\n\n        const collectionName = process.env.ASTRA_DB_COLLECTION;\n\n        const createCollection = async () => {\n            try {\n                const collectionNames = await db.listCollections({ nameOnly: true });\n                const exists = collectionNames.includes(collectionName);\n\n                if (exists) {\n                    console.log(`Collection ${collectionName} already exists.`);\n                    return;\n                }\n\n                const res = await db.createCollection(collectionName, {\n                    vector: {\n                        dimension: 1536,\n                        metric: SimilarityMetric\n                    }\n                });\n                console.log('Collection created:', res);\n            } catch (err) {\n                if (err.message.includes('already exists')) {\n                    console.log('Collection already exists, skipping.');\n                } else {\n                    throw err;\n                }\n            }\n        };\n\n        const scrapePage = async (url) => {\n            try {\n                const load = new PuppeteerWebBaseLoader(url, {\n                    launchOptions: { headless: true },\n                    gotoOptions: { waitUntil: \"domcontentloaded\" },\n                    evaluate: async (page) => {\n                        const result = await page.evaluate(() => document.body.innerHTML);\n                        return result;\n                    }\n                });\n                const docs = await load.load();\n                const content = docs[0]?.pageContent || '';\n                return content.replace(/<[^>]*>?/gm, '');\n            } catch (error) {\n                console.error(`Scrape failed for ${url}:`, error.message);\n                return '';\n            }\n        };\n\n        const loadSampleData = async () => {\n            const collection = db.collection(collectionName);\n            let insertedCount = 0;\n            for (const url of data) {\n                console.log(`Processing: ${url}`);\n                const content = await scrapePage(url);\n                if (!content) continue;\n\n                const chunks = await splitter.splitText(content);\n                for (const chunk of chunks) {\n                    if (chunk.length < 10) continue;\n\n                    try {\n                        const embedding = await openai.embeddings.create({\n                            model: \"text-embedding-3-small\",\n                            input: chunk,\n                            encoding_format: \"float\",\n                        });\n\n                        const vector = embedding.data[0].embedding;\n                        const res = await collection.insertOne({\n                            $vector: vector,\n                            text: chunk\n                        });\n                        console.log('Inserted:', res);\n                        insertedCount++;\n                    } catch (error) {\n                        console.error('Insert failed:', error.message);\n                    }\n                }\n            }\n            console.log(`Total inserted: ${insertedCount}`);\n        };\n\n        await createCollection();\n        await loadSampleData();\n        console.log('Data loading completed!');\n    } catch (error) {\n        console.error('Connect failed:', error.message);\n    }\n};","size_bytes":4763},"controllers/chat.controller.js":{"content":"const OpenAI = require('openai');\nconst { DataAPIClient } = require('@datastax/astra-db-ts');\n\nconst openai = new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY\n});\n\n// Init Astra client một lần (global)\nconst astraClient = new DataAPIClient();\nconst db = astraClient.db(process.env.ASTRA_DB_ENDPOINT, { token: process.env.ASTRA_DB_APPLICATION_TOKEN });\nconst collectionName = process.env.ASTRA_DB_COLLECTION;\n\n// Hàm helper: Tìm chunks tương tự từ DB\nconst retrieveContext = async (query) => {\n    try {\n        console.log('Step 1: Embedding query...');\n        const embedding = await openai.embeddings.create({\n            model: \"text-embedding-3-small\",\n            input: query,\n            encoding_format: \"float\",\n        });\n        const queryVector = embedding.data[0].embedding;\n        console.log('Step 2: Query vector ready, length:', queryVector.length);\n\n        console.log('Step 3: Searching DB...');\n        const cursor = db.collection(collectionName).find(\n            {},  // Filter rỗng\n            {\n                sort: { $vector: queryVector },\n                limit: 3\n            }\n        );\n\n        const results = [];\n        for await (const doc of cursor) {\n            results.push(doc);\n        }\n        console.log('Step 4: Found results:', results.length);\n\n        // Debug structure doc (chạy 1 lần, xóa sau khi OK)\n        if (results.length > 0) {\n            console.log('First doc keys:', Object.keys(results[0]));\n            console.log('First doc preview:', JSON.stringify(results[0], null, 2).substring(0, 200));\n        }\n\n        // Ghép text chunks (fallback fields, filter empty)\n        const texts = results.map(doc =>\n            doc.text || doc.body || doc.content || doc.chunk || ''  // Fallback phổ biến\n        ).filter(t => t.length > 10);  // Chỉ lấy chunks có nội dung thực (>10 chars)\n\n        const contexts = texts.join('\\n\\n---\\n\\n');\n\n        // Nếu có results nhưng texts rỗng, return debug message\n        if (results.length > 0 && texts.length === 0) {\n            return \"Ngữ cảnh tìm thấy nhưng field text rỗng (check insert ở loadDb.js).\";\n        }\n\n        return contexts || \"Không tìm thấy ngữ cảnh liên quan.\";\n    } catch (error) {\n        console.error('Retrieve context failed:', error.message);\n        console.error('Full error:', error);\n        return \"Không thể lấy ngữ cảnh từ DB.\";\n    }\n};\n\n// [POST] /api/chat - Handler chính với RAG\nconst chatWithOpenAI = async (req, res) => {\n    try {\n        const { message } = req.body;\n        if (!message) return res.status(400).json({ error: 'Message is required' });\n\n        // Bước 1: Lấy context từ DB\n        const context = await retrieveContext(message);\n        console.log('Retrieved context preview:', context.substring(0, 100) + '...');\n\n        // Bước 2: Tạo system prompt với context\n        const systemPrompt = `Tên bạn là Phúc GPT. Dựa trên ngữ cảnh sau từ dữ liệu mới nhất, \n        trả lời câu hỏi của user một cách chính xác và hữu ích. Nếu ngữ cảnh không liên quan hoặc rỗng, \n        dùng kiến thức chung của bạn nếu dữ liệu thiếu hãy suy luận theo kiến thức bạn đang có.\n\nNgữ cảnh từ DB :\n${context}`;\n\n        // Bước 3: Gọi OpenAI với messages có context\n        const response = await openai.chat.completions.create({\n            model: 'gpt-4',\n            messages: [\n                { role: 'system', content: systemPrompt },\n                { role: 'user', content: message }\n            ],\n            temperature: 0.7\n        });\n\n        res.json({ reply: response.choices[0].message.content });\n    } catch (error) {\n        console.error('Chat failed:', error);\n        res.status(500).json({ error: 'OpenAI or DB request failed' });\n    }\n};\n\nmodule.exports = { openai, chatWithOpenAI };","size_bytes":3945},"routes/chat.route.js":{"content":"const express = require('express');\nconst router = express.Router();\nconst controller = require('../controllers/chat.controller');\n\n// POST /api/chat\nrouter.post('/chat', controller.chatWithOpenAI);\n\nmodule.exports = router;\n","size_bytes":225}},"version":2}